# ğŸš€ Quick Training Guide - RTX 3050

Train nhanh vá»›i 50% dataset trÃªn RTX 3050 (4GB VRAM).

## âš¡ Quick Start

```bash
# Cháº¡y training ngay
python scripts/train_half_dataset.py
```

ÄÆ¡n giáº£n váº­y thÃ´i! Script sáº½ tá»± Ä‘á»™ng:
- DÃ¹ng 50% training data (960 samples thay vÃ¬ 1920)
- Model nháº¹ hÆ¡n (256 dim thay vÃ¬ 512)
- Batch size nhá» (4 thay vÃ¬ 8-16)
- 50 epochs (thay vÃ¬ 100)

## ğŸ“Š ThÃ´ng sá»‘ tá»‘i Æ°u cho RTX 3050

### Model Architecture (Lightweight)
```
Audio Branch:    256 dim, 6 layers  (was 512 dim, 8 layers)
Visual Branch:   256 dim, 3 layers  (was 512 dim, 4 layers)
Fusion:          512 dim, 3 layers  (was 1024 dim, 4 layers)
Total params:    ~50M               (was ~150M)
```

### Training Config
```
Batch size:      4
Epochs:          50
Learning rate:   1e-4
Mixed precision: FP16 (enabled)
Gradient clip:   1.0
```

### Dataset Split (50% training data)
```
Train:  960 samples  (actors 1-16, random 50%)
Val:    480 samples  (actors 17-20, full)
Test:   480 samples  (actors 21-24, full)
```

## â±ï¸ Expected Performance

### Training Time
- **Per epoch**: ~2-3 minutes
- **Total (50 epochs)**: ~1.5-2 hours
- **VRAM usage**: ~3.5 GB (safe for 4GB)

### Expected Metrics (after 50 epochs)
- **UAR**: 0.55-0.65 (lower than full dataset, but acceptable)
- **Accuracy**: 0.60-0.70
- **Val UAR**: Should improve steadily

## ğŸ“ Output

Training sáº½ táº¡o folder:
```
checkpoints/half_dataset_rtx3050/
â”œâ”€â”€ config.json              # Training configuration
â”œâ”€â”€ history.json             # Training history
â”œâ”€â”€ best_model.pt            # Best model (highest val UAR)
â”œâ”€â”€ checkpoint_epoch_10.pt   # Checkpoint at epoch 10
â”œâ”€â”€ checkpoint_epoch_20.pt   # Checkpoint at epoch 20
â”œâ”€â”€ checkpoint_epoch_30.pt   # Checkpoint at epoch 30
â”œâ”€â”€ checkpoint_epoch_40.pt   # Checkpoint at epoch 40
â”œâ”€â”€ checkpoint_epoch_50.pt   # Checkpoint at epoch 50
â””â”€â”€ test_results.json        # Final test results
```

## ğŸ“ˆ Monitoring Progress

Script sáº½ hiá»ƒn thá»‹ realtime:

```
Epoch 1/50
----------------------------------------------------------------------
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 240/240 [02:15<00:00, loss=2.0543]
Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 120/120 [00:30<00:00]

Results:
  Train Loss: 2.0543
  Val Loss:   1.8234
  Accuracy:   0.3542
  UAR:        0.3125
  Time:       165.3s
  ETA: 123.8 minutes
```

## ğŸ¯ Sau khi training xong

### 1. Check results
```python
import json

# Load history
with open("checkpoints/half_dataset_rtx3050/history.json") as f:
    history = json.load(f)

print(f"Best UAR: {max(history['val_uar']):.4f}")
print(f"Final train loss: {history['train_loss'][-1]:.4f}")
```

### 2. Visualize training
```python
import matplotlib.pyplot as plt

plt.figure(figsize=(12, 4))

plt.subplot(1, 2, 1)
plt.plot(history['train_loss'], label='Train')
plt.plot(history['val_loss'], label='Val')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.title('Loss')

plt.subplot(1, 2, 2)
plt.plot(history['val_uar'])
plt.xlabel('Epoch')
plt.ylabel('UAR')
plt.title('Validation UAR')

plt.tight_layout()
plt.savefig('training_curves.png')
plt.show()
```

### 3. Test inference
```python
import torch
from models import MultimodalFER, VisualBranchConfig, LFM2FusionConfig, AudioBranchConfig

# Load best model
checkpoint = torch.load("checkpoints/half_dataset_rtx3050/best_model.pt")

# Create model (same config as training)
audio_config = AudioBranchConfig(feature_dim=256, num_layers=6)
visual_config = VisualBranchConfig(feature_dim=256, temporal_depth=3)
fusion_config = LFM2FusionConfig(
    num_layers=3, hidden_dim=512,
    audio_dim=256, visual_dim=256, output_dim=256
)

model = MultimodalFER(
    audio_config=audio_config,
    visual_config=visual_config,
    fusion_config=fusion_config,
    num_classes=8,
)

model.load_state_dict(checkpoint["model_state_dict"])
model.eval()

print("Model loaded successfully!")
```

## ğŸ”§ Troubleshooting

### Náº¿u váº«n bá»‹ OOM (Out of Memory)

Giáº£m batch size:
```python
# Edit line 202 in scripts/train_half_dataset.py
"batch_size": 2,  # Change from 4 to 2
```

### Náº¿u muá»‘n train nhanh hÆ¡n

Giáº£m epochs:
```python
# Edit line 203 in scripts/train_half_dataset.py
"num_epochs": 30,  # Change from 50 to 30
```

### Náº¿u muá»‘n dÃ¹ng full dataset

Sá»­ dá»¥ng script gá»‘c:
```bash
python scripts/train_ravdess.py \
    --data_dir data/ravdess \
    --batch_size 4 \
    --epochs 50 \
    --audio_dim 256 \
    --visual_dim 256 \
    --fusion_hidden_dim 512 \
    --num_audio_layers 6 \
    --num_visual_layers 3 \
    --num_fusion_layers 3
```

## ğŸ’¡ Tips

### TÄƒng performance
1. **Close other apps** Ä‘á»ƒ giáº£i phÃ³ng VRAM
2. **Disable browser** náº¿u cÃ³ GPU acceleration
3. **Set num_workers=0** náº¿u CPU yáº¿u

### Monitor GPU
```bash
# Trong terminal khÃ¡c
watch -n 1 nvidia-smi
```

### Save VRAM
```python
# Náº¿u cáº§n, cÃ³ thá»ƒ giáº£m thÃªm:
- audio_dim: 256 -> 128
- visual_dim: 256 -> 128
- fusion_hidden_dim: 512 -> 256
```

## ğŸ“Š So sÃ¡nh vá»›i Full Training

| Metric | Half Dataset (50 epochs) | Full Dataset (100 epochs) |
|--------|--------------------------|---------------------------|
| Training samples | 960 | 1920 |
| Training time | 1.5-2 hours | 3-4 hours |
| Expected UAR | 0.55-0.65 | 0.65-0.75 |
| VRAM usage | ~3.5 GB | ~3.8 GB |
| Model size | ~50M params | ~150M params |

## âœ… Advantages

- âœ… **Nhanh**: 1.5-2 giá» thay vÃ¬ 3-4 giá»
- âœ… **An toÃ n**: Cháº¯c cháº¯n khÃ´ng OOM
- âœ… **Äá»§ dÃ¹ng**: UAR 0.55-0.65 váº«n acceptable
- âœ… **ÄÆ¡n giáº£n**: Chá»‰ 1 command

## ğŸ“ Next Steps

Sau khi train xong:

1. **Evaluate**: Check test results trong `test_results.json`
2. **Inference**: DÃ¹ng model cho prediction
3. **Fine-tune**: Náº¿u cáº§n, train thÃªm vá»›i learning rate nhá» hÆ¡n
4. **Full training**: Náº¿u káº¿t quáº£ tá»‘t, cÃ³ thá»ƒ train full dataset sau

## ğŸ†˜ Need Help?

- Check `history.json` Ä‘á»ƒ xem training progress
- Check `config.json` Ä‘á»ƒ xem configuration
- Run `python scripts/test_local_setup.py` Ä‘á»ƒ verify setup
- Check GPU usage: `nvidia-smi`

---

**Ready to train?**
```bash
python scripts/train_half_dataset.py
```

Ngá»“i uá»‘ng cÃ  phÃª vÃ  chá» 1.5-2 giá»! â˜•
