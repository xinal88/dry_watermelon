# ğŸ¯ Local Training Guide

HÆ°á»›ng dáº«n train model trÃªn mÃ¡y local hoáº·c qua Kiro IDE káº¿t ná»‘i vá»›i Colab.

## ğŸ“‹ YÃªu cáº§u

1. **Dá»¯ liá»‡u**: RAVDESS dataset trong folder `data/ravdess/`
2. **GPU**: CUDA-compatible GPU (khuyáº¿n nghá»‹)
3. **Dependencies**: ÄÃ£ cÃ i Ä‘áº·t táº¥t cáº£ packages

## ğŸš€ CÃ¡ch 1: Cháº¡y Training Script

### Quick Start

```bash
# Basic training
python scripts/train_ravdess.py --data_dir data/ravdess --epochs 100

# Custom configuration
python scripts/train_ravdess.py \
    --data_dir data/ravdess \
    --batch_size 16 \
    --epochs 100 \
    --lr 1e-4 \
    --save_dir checkpoints/my_experiment
```

### Tham sá»‘ quan trá»ng

```bash
# Data
--data_dir data/ravdess          # ÄÆ°á»ng dáº«n Ä‘áº¿n dá»¯ liá»‡u
--modality speech                # "speech" hoáº·c "song"
--use_audio                      # Sá»­ dá»¥ng audio modality

# Training
--batch_size 8                   # Batch size (8-16 cho GPU nhá»)
--epochs 100                     # Sá»‘ epochs
--lr 1e-4                        # Learning rate
--num_workers 2                  # DataLoader workers

# Model (Lightweight cho GPU nhá»)
--audio_dim 512
--visual_dim 512
--fusion_hidden_dim 1024
--num_audio_layers 8
--num_visual_layers 4
--num_fusion_layers 4

# Optimization
--use_amp                        # Mixed precision (FP16)
--max_grad_norm 1.0             # Gradient clipping

# Checkpointing
--save_dir checkpoints/ravdess_local
--save_every 10                  # LÆ°u má»—i 10 epochs
--resume checkpoints/xxx.pt      # Resume tá»« checkpoint
```

## ğŸ”§ CÃ¡ch 2: Test trÆ°á»›c khi Train

### 1. Kiá»ƒm tra dá»¯ liá»‡u

```python
from pathlib import Path

data_path = Path("data/ravdess")
print(f"Data exists: {data_path.exists()}")

speech_folders = list(data_path.glob("Video_Speech_Actor_*"))
print(f"Found {len(speech_folders)} actors")
```

### 2. Test dataloader

```python
from data.ravdess_dataset import create_ravdess_dataloaders

train_loader, val_loader, test_loader = create_ravdess_dataloaders(
    data_dir="data/ravdess",
    modality="speech",
    batch_size=4,
    num_workers=0,  # 0 for debugging
    use_audio=True,
)

print(f"Train: {len(train_loader.dataset)} samples")
print(f"Val: {len(val_loader.dataset)} samples")
print(f"Test: {len(test_loader.dataset)} samples")

# Test one batch
audio, video, labels, metadata = next(iter(train_loader))
print(f"\nBatch shapes:")
print(f"  Audio: {audio.shape}")
print(f"  Video: {video.shape}")
print(f"  Labels: {labels.shape}")
```

### 3. Test model

```python
import torch
from models import MultimodalFER, VisualBranchConfig, LFM2FusionConfig, AudioBranchConfig

# Create lightweight model
audio_config = AudioBranchConfig(feature_dim=512, num_layers=8)
visual_config = VisualBranchConfig(feature_dim=512, temporal_depth=4)
fusion_config = LFM2FusionConfig(
    num_layers=4,
    hidden_dim=1024,
    audio_dim=512,
    visual_dim=512,
    output_dim=512,
)

model = MultimodalFER(
    audio_config=audio_config,
    visual_config=visual_config,
    fusion_config=fusion_config,
    num_classes=8,
)

model.print_summary()

# Test forward pass
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = model.to(device)

audio = torch.randn(2, 48000).to(device)  # 2 samples, 3 seconds @ 16kHz
video = torch.randn(2, 16, 3, 224, 224).to(device)  # 2 samples, 16 frames

outputs = model(audio, video)
print(f"\nOutput shape: {outputs.shape}")  # Should be [2, 8]
```

## ğŸ“Š Monitoring Training

### Xem training progress

```python
import json
from pathlib import Path

# Load history
history_path = Path("checkpoints/ravdess_local/history.json")
if history_path.exists():
    with open(history_path) as f:
        history = json.load(f)
    
    print(f"Epochs trained: {len(history['train_loss'])}")
    print(f"Best UAR: {max(history['val_uar']):.4f}")
    print(f"Latest train loss: {history['train_loss'][-1]:.4f}")
    print(f"Latest val loss: {history['val_loss'][-1]:.4f}")
```

### Visualize training curves

```python
import matplotlib.pyplot as plt

fig, axes = plt.subplots(1, 2, figsize=(12, 4))

# Loss
axes[0].plot(history['train_loss'], label='Train')
axes[0].plot(history['val_loss'], label='Val')
axes[0].set_xlabel('Epoch')
axes[0].set_ylabel('Loss')
axes[0].legend()
axes[0].set_title('Training Loss')

# UAR
axes[1].plot(history['val_uar'])
axes[1].set_xlabel('Epoch')
axes[1].set_ylabel('UAR')
axes[1].set_title('Validation UAR')

plt.tight_layout()
plt.savefig('training_curves.png')
plt.show()
```

## ğŸ”„ Resume Training

```bash
# Resume tá»« checkpoint cuá»‘i cÃ¹ng
python scripts/train_ravdess.py \
    --data_dir data/ravdess \
    --resume checkpoints/ravdess_local/checkpoint_epoch_50.pt \
    --epochs 100
```

## ğŸ’¡ Tips

### Náº¿u gáº·p Out of Memory (OOM)

1. Giáº£m batch size: `--batch_size 4`
2. Giáº£m sá»‘ workers: `--num_workers 0`
3. Giáº£m model size:
   ```bash
   --num_audio_layers 6 \
   --num_visual_layers 3 \
   --num_fusion_layers 3 \
   --fusion_hidden_dim 512
   ```

### TÄƒng tá»‘c training

1. TÄƒng batch size (náº¿u cÃ³ Ä‘á»§ VRAM): `--batch_size 16`
2. Sá»­ dá»¥ng mixed precision: `--use_amp`
3. TÄƒng num_workers: `--num_workers 4`

### Debug mode

```bash
# Train vá»›i 1 epoch Ä‘á»ƒ test
python scripts/train_ravdess.py \
    --data_dir data/ravdess \
    --batch_size 2 \
    --epochs 1 \
    --num_workers 0 \
    --save_dir checkpoints/debug
```

## ğŸ“ Output Structure

```
checkpoints/ravdess_local/
â”œâ”€â”€ config.json                    # Training configuration
â”œâ”€â”€ history.json                   # Training history
â”œâ”€â”€ best_model.pt                  # Best model (highest UAR)
â”œâ”€â”€ checkpoint_epoch_10.pt         # Checkpoint at epoch 10
â”œâ”€â”€ checkpoint_epoch_20.pt         # Checkpoint at epoch 20
â””â”€â”€ ...
```

## ğŸ¯ Expected Results

Vá»›i RAVDESS speech dataset:

- **Train samples**: ~960 videos (actors 1-16)
- **Val samples**: ~240 videos (actors 17-20)
- **Test samples**: ~240 videos (actors 21-24)

Expected performance sau 100 epochs:
- **UAR**: 0.65-0.75
- **Accuracy**: 0.70-0.80
- **Training time**: 2-4 giá» (T4 GPU)

## ğŸ› Troubleshooting

### Lá»—i: "Loaded 0 videos"

```python
# Check data path
from pathlib import Path
data_path = Path("data/ravdess")
print(f"Exists: {data_path.exists()}")
print(f"Folders: {list(data_path.glob('Video_Speech_Actor_*'))[:3]}")
```

### Lá»—i: "CUDA out of memory"

Giáº£m batch size hoáº·c model size (xem Tips trÃªn).

### Lá»—i: "ffmpeg not found"

```bash
# Install ffmpeg
# Ubuntu/Debian
sudo apt-get install ffmpeg

# macOS
brew install ffmpeg

# Windows
# Download from https://ffmpeg.org/download.html
```

## ğŸ“ Support

Náº¿u gáº·p váº¥n Ä‘á», check:
1. `TEST_STATUS.md` - Test results
2. `TRAINING_GUIDE.md` - Detailed training guide
3. `QUICK_REFERENCE.md` - Quick commands
