# üéØ H∆∞·ªõng D·∫´n S·ª≠ D·ª•ng train_dry_watermelon_v1.ipynb

## ‚úÖ C√°c C·∫£i Ti·∫øn So V·ªõi Phi√™n B·∫£n C≈©

### V·∫•n ƒê·ªÅ ƒê√£ Fix:
1. ‚úÖ **L·ªói "Loaded 0 videos"** - ƒê√£ fix dataset loader h·ªó tr·ª£ c·∫£ `Actor_*` v√† `Video_Speech_Actor_*`
2. ‚úÖ **Mount Drive trong Colab IDE** - T·ª± ƒë·ªông detect v√† mount ƒë√∫ng c√°ch
3. ‚úÖ **Validation d·ªØ li·ªáu** - Ki·ªÉm tra d·ªØ li·ªáu TR∆Ø·ªöC KHI t·∫°o model
4. ‚úÖ **Error handling t·ªët h∆°n** - Th√¥ng b√°o l·ªói r√µ r√†ng, d·ªÖ debug
5. ‚úÖ **T∆∞∆°ng th√≠ch c·∫£ Colab web v√† Colab IDE extension**

### C√°c T√≠nh NƒÉng M·ªõi:
- üîç Auto-detect m√¥i tr∆∞·ªùng Colab
- üìä Validation d·ªØ li·ªáu chi ti·∫øt
- üíæ T·ª± ƒë·ªông save checkpoints
- üìà Visualization training curves
- üéØ Test set evaluation
- üì¶ Easy download checkpoints

## üöÄ C√°ch S·ª≠ D·ª•ng

### B∆∞·ªõc 1: Push Code L√™n GitHub

```bash
# Add files
git add data/ravdess_dataset.py
git add train_dry_watermelon_v1.ipynb
git add HUONG_DAN_COLAB_V1.md

# Commit
git commit -m "Add v1 notebook with fixes for Colab IDE"

# Push
git push origin main
```

### B∆∞·ªõc 2: M·ªü Notebook Trong Colab

**Option A: Colab Web (Khuy·∫øn ngh·ªã)**
1. V√†o https://colab.research.google.com/
2. File ‚Üí Open notebook ‚Üí GitHub
3. Nh·∫≠p: `xinal88/dry_watermelon`
4. Ch·ªçn: `train_dry_watermelon_v1.ipynb`

**Option B: Colab IDE Extension (VS Code)**
1. M·ªü VS Code
2. C√†i extension: "Colab"
3. Open file: `train_dry_watermelon_v1.ipynb`
4. Click "Open in Colab"

### B∆∞·ªõc 3: Ch·ªçn GPU Runtime

1. Click `Runtime` ‚Üí `Change runtime type`
2. Ch·ªçn `T4 GPU` (mi·ªÖn ph√≠) ho·∫∑c `A100` (Colab Pro)
3. Click `Save`

### B∆∞·ªõc 4: Ch·∫°y T·ª´ng Cell

**QUAN TR·ªåNG**: Ch·∫°y theo th·ª© t·ª±, KH√îNG skip cell n√†o!

#### Cell 1: Environment Check ‚úÖ
```python
# Ki·ªÉm tra m√¥i tr∆∞·ªùng
Running in Colab: True
‚úì Colab environment detected
```

#### Cell 2: Clone Repository ‚úÖ
```python
# Clone code t·ª´ GitHub
Cloning repository...
‚úì Repository cloned
```

#### Cell 3: Mount Google Drive ‚ö†Ô∏è QUAN TR·ªåNG!
```python
# C·∫¨P NH·∫¨T ƒê∆Ø·ªúNG D·∫™N N√ÄY!
RAVDESS_PATH = "/content/drive/MyDrive/[HUST]_Facial_Expression_Recognition/Dataset/Multimodal_DFER/RAVDESS"
```

**N·∫øu ƒë∆∞·ªùng d·∫´n c·ªßa b·∫°n kh√°c, s·ª≠a l·∫°i cho ƒë√∫ng!**

K·∫øt qu·∫£ mong ƒë·ª£i:
```
‚úì Google Drive already mounted
‚úì RAVDESS path found: /content/drive/MyDrive/...
‚úì Found 24 Actor folders
  Sample: ['Actor_01', 'Actor_02', 'Actor_03']
‚úì Created symlink: data/ravdess -> Google Drive
```

#### Cell 4: Install Dependencies ‚úÖ
```python
# C√†i ƒë·∫∑t packages
Installing dependencies...
‚úì All dependencies installed!
```

#### Cell 5: Import Libraries ‚úÖ
```python
# Import modules
‚úì All imports successful!
```

#### Cell 6: Configuration ‚öôÔ∏è
```python
# Xem c·∫•u h√¨nh training
TRAINING CONFIGURATION
======================================================================
  data_dir: /content/drive/MyDrive/.../RAVDESS
  batch_size: 16
  num_epochs: 40
  ...
```

**C√≥ th·ªÉ ch·ªânh s·ª≠a:**
- `batch_size`: 8-16 cho T4, 32-64 cho A100
- `num_epochs`: S·ªë epoch (40 = ~2-3 gi·ªù)
- `use_audio`: True/False (c√≥ d√πng audio kh√¥ng)

#### Cell 7: Validate Data ‚úÖ QUAN TR·ªåNG!
```python
# Ki·ªÉm tra d·ªØ li·ªáu
Found 24 video folders:
  Sample folders: ['Actor_01', 'Actor_02', ...]
  Videos in Actor_01: 60

‚úÖ Data validation PASSED!
‚úÖ Ready to create dataloaders
```

**N·∫øu l·ªói ·ªü ƒë√¢y:**
- Ki·ªÉm tra l·∫°i `RAVDESS_PATH` ·ªü Cell 3
- ƒê·∫£m b·∫£o c√≥ folders `Actor_01` ƒë·∫øn `Actor_24`
- ƒê·∫£m b·∫£o m·ªói folder c√≥ file `.mp4`

#### Cell 8: Create Model ‚úÖ
```python
# T·∫°o model
Creating model...
======================================================================
Multimodal FER Model Summary
======================================================================
Total: 149,021,194 params (149.02M)
```

#### Cell 9: Create Dataloaders ‚úÖ KEY CELL!
```python
# T·∫°o dataloaders
Creating dataloaders...
Loaded 2008 videos for train split (speech)
Loaded 480 videos for val split (speech)
Loaded 480 videos for test split (speech)

‚úÖ Dataloaders created successfully!
  Train: 2008 samples (125 batches)
  Val:   480 samples (30 batches)
  Test:  480 samples (30 batches)
```

**N·∫øu v·∫´n th·∫•y "Loaded 0 videos":**
1. Quay l·∫°i Cell 7, check output
2. Ki·ªÉm tra `RAVDESS_PATH` ·ªü Cell 3
3. Ch·∫°y l·∫°i Cell 3 ‚Üí Cell 7 ‚Üí Cell 9

#### Cell 10-12: Training Setup & Functions ‚úÖ
```python
# Setup optimizer, loss, metrics
‚úì Training setup complete!
‚úì Training functions defined
```

#### Cell 13: Main Training Loop üöÄ
```python
# B·∫ÆT ƒê·∫¶U TRAINING - 2-3 GI·ªú!
STARTING TRAINING
======================================================================
Start time: 2026-01-05 10:00:00
Total epochs: 40
======================================================================

Epoch 1/40
Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 125/125 [03:24<00:00]
Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 30/30 [00:32<00:00]

Results:
  Train Loss: 1.8234 | Train Acc: 32.50%
  Val Loss: 1.6543 | Val Acc: 38.20%
  Val F1: 0.3456
  ‚úì New best model! Saved to: checkpoints/ravdess_speech_t4/best_model.pt

...

Epoch 40/40
Results:
  Train Loss: 0.2134 | Train Acc: 92.50%
  Val Loss: 0.6234 | Val Acc: 78.50%
  Val F1: 0.7623
  ‚úì Checkpoint saved: checkpoint_epoch_40.pt

======================================================================
TRAINING COMPLETE!
======================================================================
Duration: 2:34:15
Best Val Accuracy: 78.50%
```

#### Cell 14: Plot Results üìà
```python
# V·∫Ω bi·ªÉu ƒë·ªì
‚úì Plot saved to: checkpoints/ravdess_speech_t4/training_curves.png
```

#### Cell 15: Test Evaluation üß™
```python
# ƒê√°nh gi√° tr√™n test set
EVALUATING ON TEST SET
======================================================================
‚úì Loaded best model from epoch 35

Test Results:
  Loss: 0.6543
  Accuracy: 76.25%
  F1 Score: 0.7412
  Precision: 0.7523
  Recall: 0.7301
```

#### Cell 16: Download Checkpoints üíæ
```python
# Download v·ªÅ m√°y
Preparing files for download...
Downloading checkpoints.zip...
‚úì Download complete!
```

## üìä K·∫øt Qu·∫£ Mong ƒê·ª£i

### T4 GPU (Free Colab)
- **Th·ªùi gian**: 2-3 gi·ªù (40 epochs)
- **Memory**: 8-10 GB VRAM
- **Accuracy**: 75-80%
- **F1 Score**: 0.73-0.78

### A100 GPU (Colab Pro)
- **Th·ªùi gian**: 1 gi·ªù (40 epochs)
- **Memory**: 15-20 GB VRAM
- **Accuracy**: 80-85%
- **F1 Score**: 0.78-0.83

## üîß Troubleshooting

### L·ªói 1: "Loaded 0 videos"

**Nguy√™n nh√¢n**: ƒê∆∞·ªùng d·∫´n RAVDESS sai ho·∫∑c c·∫•u tr√∫c folder kh√¥ng ƒë√∫ng

**Gi·∫£i ph√°p**:
1. Ki·ªÉm tra Cell 3, s·ª≠a `RAVDESS_PATH`
2. Ch·∫°y cell n√†y ƒë·ªÉ ki·ªÉm tra:
```python
!ls -la /content/drive/MyDrive/[HUST]_Facial_Expression_Recognition/Dataset/Multimodal_DFER/RAVDESS/ | head -20
```
3. Ph·∫£i th·∫•y folders: `Actor_01`, `Actor_02`, ..., `Actor_24`

### L·ªói 2: Out of Memory (OOM)

**Nguy√™n nh√¢n**: Batch size qu√° l·ªõn

**Gi·∫£i ph√°p**: S·ª≠a Cell 6:
```python
CONFIG = {
    "batch_size": 8,  # Gi·∫£m t·ª´ 16 xu·ªëng 8
    "gradient_accumulation_steps": 2,  # B√π l·∫°i b·∫±ng accumulation
}
```

### L·ªói 3: Training qu√° ch·∫≠m

**Gi·∫£i ph√°p 1**: T·∫Øt audio
```python
CONFIG = {
    "use_audio": False,  # Visual-only, nhanh h∆°n
}
```

**Gi·∫£i ph√°p 2**: Gi·∫£m model size
```python
CONFIG = {
    "num_audio_layers": 6,  # T·ª´ 8 xu·ªëng 6
    "num_visual_layers": 3,  # T·ª´ 4 xu·ªëng 3
    "num_fusion_layers": 3,  # T·ª´ 4 xu·ªëng 3
}
```

### L·ªói 4: Colab disconnect

**Nguy√™n nh√¢n**: Session timeout (12 gi·ªù)

**Gi·∫£i ph√°p**:
1. D√πng Colab Pro (24 gi·ªù)
2. Ho·∫∑c gi·∫£m epochs xu·ªëng 20
3. Checkpoints ƒë√£ save, c√≥ th·ªÉ resume sau

### L·ªói 5: Google Drive kh√¥ng mount ƒë∆∞·ª£c

**Gi·∫£i ph√°p**:
1. Ch·∫°y l·∫°i Cell 3
2. Click v√†o link authorize
3. Copy code v√† paste v√†o
4. N·∫øu v·∫´n l·ªói, restart runtime v√† ch·∫°y l·∫°i t·ª´ ƒë·∫ßu

## üìÅ Files ƒê∆∞·ª£c T·∫°o Ra

Sau khi training xong, trong folder `checkpoints/ravdess_speech_t4/`:

```
checkpoints/ravdess_speech_t4/
‚îú‚îÄ‚îÄ best_model.pt              # Model t·ªët nh·∫•t (val acc cao nh·∫•t)
‚îú‚îÄ‚îÄ final_model.pt             # Model epoch cu·ªëi
‚îú‚îÄ‚îÄ checkpoint_epoch_10.pt     # Checkpoint epoch 10
‚îú‚îÄ‚îÄ checkpoint_epoch_20.pt     # Checkpoint epoch 20
‚îú‚îÄ‚îÄ checkpoint_epoch_30.pt     # Checkpoint epoch 30
‚îú‚îÄ‚îÄ checkpoint_epoch_40.pt     # Checkpoint epoch 40
‚îú‚îÄ‚îÄ config.json                # C·∫•u h√¨nh training
‚îú‚îÄ‚îÄ training_history.json      # L·ªãch s·ª≠ metrics
‚îú‚îÄ‚îÄ training_curves.png        # Bi·ªÉu ƒë·ªì
‚îî‚îÄ‚îÄ test_results.json          # K·∫øt qu·∫£ test set
```

## üí° Tips

1. **Ki·ªÉm tra GPU tr∆∞·ªõc khi train**:
```python
!nvidia-smi
```

2. **Monitor VRAM usage**:
```python
!watch -n 1 nvidia-smi  # Ctrl+C ƒë·ªÉ tho√°t
```

3. **Test v·ªõi 5 epochs tr∆∞·ªõc**:
```python
CONFIG["num_epochs"] = 5  # Test nhanh
```

4. **Keep Drive mounted**:
- Kh√¥ng unmount Drive trong khi training
- Kh√¥ng ƒë√≥ng tab Colab

5. **Save checkpoints th∆∞·ªùng xuy√™n**:
```python
CONFIG["save_every"] = 5  # Save m·ªói 5 epochs
```

## ‚úÖ Checklist Tr∆∞·ªõc Khi Train

- [ ] ƒê√£ push code l√™n GitHub
- [ ] ƒê√£ m·ªü notebook trong Colab
- [ ] ƒê√£ ch·ªçn T4 GPU runtime
- [ ] ƒê√£ mount Google Drive
- [ ] ƒê√£ c·∫≠p nh·∫≠t `RAVDESS_PATH` ƒë√∫ng
- [ ] Cell 7 validation PASSED
- [ ] Cell 9 dataloaders created (2008/480/480 samples)
- [ ] ƒê√£ ƒë·ªçc h∆∞·ªõng d·∫´n troubleshooting
- [ ] S·∫µn s√†ng ch·ªù 2-3 gi·ªù

## üéØ T√≥m T·∫Øt

1. **Push code**: `git push origin main`
2. **M·ªü Colab**: https://colab.research.google.com/
3. **Ch·ªçn GPU**: T4 ho·∫∑c A100
4. **S·ª≠a path**: Cell 3 - `RAVDESS_PATH`
5. **Ch·∫°y t·∫•t c·∫£ cells**: Shift+Enter t·ª´ng cell
6. **Ch·ªù training**: 2-3 gi·ªù
7. **Download model**: Cell 16
8. **Xong!** üéâ

## üìû N·∫øu V·∫´n G·∫∑p L·ªói

Ki·ªÉm tra l·∫°i:
1. ‚úÖ ƒê√£ push code m·ªõi nh·∫•t l√™n GitHub?
2. ‚úÖ Cell 7 validation c√≥ PASSED kh√¥ng?
3. ‚úÖ Cell 9 c√≥ load ƒë∆∞·ª£c 2008 samples kh√¥ng?
4. ‚úÖ `RAVDESS_PATH` c√≥ ƒë√∫ng kh√¥ng?

N·∫øu v·∫´n l·ªói, ch·ª•p m√†n h√¨nh error v√† ki·ªÉm tra l·∫°i t·ª´ng b∆∞·ªõc!

---

**Ch√∫c b·∫°n training th√†nh c√¥ng! üöÄ**
