# ğŸš€ HÆ°á»›ng Dáº«n Train TrÃªn Colab - Cá»°C Ká»² ÄÆ N GIáº¢N

## âœ… Data Pipeline - ÄÃƒ HOÃ€N THIá»†N 100%

### Data Loader CÃ³ Sáºµn:

```
âœ… data/simple_ravdess_dataset.py
   â”œâ”€ Tá»± Ä‘á»™ng tÃ¬m táº¥t cáº£ .mp4 files
   â”œâ”€ Parse filename Ä‘á»ƒ láº¥y emotion label
   â”œâ”€ Extract audio tá»« video (ffmpeg)
   â”œâ”€ Extract video frames (opencv)
   â”œâ”€ Split train/val/test theo actor number
   â””â”€ Hoáº¡t Ä‘á»™ng vá»›i Báº¤T Ká»² cáº¥u trÃºc thÆ° má»¥c nÃ o!

âœ… data/ravdess_dataset.py
   â”œâ”€ Version Ä‘áº§y Ä‘á»§ vá»›i nhiá»u options
   â””â”€ Há»— trá»£ cáº£ speech vÃ  song modalities
```

### Cáº¥u TrÃºc RAVDESS Dataset:

```
RAVDESS/
â”œâ”€â”€ Video_Speech_Actor_01/
â”‚   â”œâ”€â”€ 01-01-01-01-01-01-01.mp4
â”‚   â”œâ”€â”€ 01-01-01-01-01-02-01.mp4
â”‚   â””â”€â”€ ...
â”œâ”€â”€ Video_Speech_Actor_02/
â”‚   â””â”€â”€ ...
â””â”€â”€ Video_Speech_Actor_24/
    â””â”€â”€ ...

Hoáº·c:
RAVDESS/
â”œâ”€â”€ Actor_01/
â”‚   â”œâ”€â”€ 01-01-01-01-01-01-01.mp4
â”‚   â””â”€â”€ ...
â””â”€â”€ ...

Hoáº·c Báº¤T Ká»² cáº¥u trÃºc nÃ o - loader sáº½ tá»± tÃ¬m!
```

### Filename Format:

```
01-01-03-02-01-01-12.mp4
â”‚  â”‚  â”‚  â”‚  â”‚  â”‚  â””â”€ Actor (01-24)
â”‚  â”‚  â”‚  â”‚  â”‚  â””â”€â”€â”€â”€ Repetition (01 or 02)
â”‚  â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€ Statement (01 or 02)
â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Intensity (01=normal, 02=strong)
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Emotion (01-08)
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Vocal (01=speech, 02=song)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Modality (01=audio-video)

Emotions:
01 = neutral
02 = calm
03 = happy
04 = sad
05 = angry
06 = fearful
07 = disgust
08 = surprised
```

---

## ğŸ¯ CÃCH Sá»¬ Dá»¤NG - CHá»ˆ 3 BÆ¯á»šC!

### BÆ°á»›c 1: Setup Colab (5 phÃºt)

```python
# Cell 1: Mount Google Drive
from google.colab import drive
drive.mount('/content/drive')
```

```python
# Cell 2: Clone repository
!git clone https://github.com/your-username/multimodal-fer.git
%cd multimodal-fer
```

```python
# Cell 3: Install dependencies
!pip install -q torch torchvision torchaudio
!pip install -q transformers timm einops
!pip install -q opencv-python librosa soundfile torchaudio
!pip install -q tqdm scikit-learn

print("âœ… Dependencies installed!")
```

### BÆ°á»›c 2: Update Configuration (1 phÃºt)

Má»Ÿ file `colab_train_easy.py` vÃ  chá»‰nh sá»­a dÃ²ng nÃ y:

```python
CONFIG = {
    # ğŸ”¥ CHá»ˆ Cáº¦N THAY Äá»”I DÃ’NG NÃ€Y!
    "RAVDESS_PATH": "/content/drive/MyDrive/RAVDESS",  # <-- ÄÆ°á»ng dáº«n cá»§a báº¡n
    
    # CÃ¡c settings khÃ¡c (cÃ³ thá»ƒ giá»¯ nguyÃªn)
    "SAVE_DIR": "/content/drive/MyDrive/checkpoints/multimodal_fer",
    "model_type": "lightweight",
    "batch_size": 8,
    "max_epochs": 50,
    # ...
}
```

**VÃ­ dá»¥ cÃ¡c Ä‘Æ°á»ng dáº«n phá»• biáº¿n:**
```python
# Náº¿u báº¡n upload vÃ o thÆ° má»¥c gá»‘c cá»§a Drive:
"RAVDESS_PATH": "/content/drive/MyDrive/RAVDESS"

# Náº¿u báº¡n upload vÃ o subfolder:
"RAVDESS_PATH": "/content/drive/MyDrive/Datasets/RAVDESS"

# Náº¿u báº¡n upload vÃ o shared drive:
"RAVDESS_PATH": "/content/drive/Shareddrives/MyTeam/RAVDESS"
```

### BÆ°á»›c 3: Run Training! (2 giá»)

```python
# Cell 4: Start training
!python colab_train_easy.py
```

**ÄÃ³ lÃ  táº¥t cáº£!** Script sáº½ tá»± Ä‘á»™ng:
- âœ… Kiá»ƒm tra GPU
- âœ… Verify dataset
- âœ… Load data
- âœ… Create model
- âœ… Train
- âœ… Save checkpoints
- âœ… Test

---

## ğŸ“Š Output Máº«u

```
================================================================================
ğŸš€ MULTIMODAL FER TRAINING - EASY COLAB SETUP
================================================================================

âœ… Device: cuda
âœ… GPU: Tesla A100-SXM4-40GB
âœ… VRAM: 40.0 GB

ğŸ“ Checking RAVDESS dataset...
   Path: /content/drive/MyDrive/RAVDESS
âœ… Found 1440 total videos
âœ… Save directory: /content/drive/MyDrive/checkpoints/multimodal_fer

================================================================================
âœ… SETUP COMPLETE - READY TO TRAIN!
================================================================================

[1/4] Creating model...
================================================================================
Building Multimodal FER Model
================================================================================

[1/4] Audio Branch...
[OK] Audio Branch initialized

[2/4] Visual Branch...
[OK] Visual Branch initialized

[3/4] LFM2 Fusion...
[OK] LFM2 Fusion initialized

[4/4] Emotion Classifier...
[OK] Emotion Classifier initialized

================================================================================
[SUCCESS] Multimodal FER Model Built Successfully!
================================================================================

[2/4] Loading data...
Loaded 960 videos for train split (speech)
Loaded 192 videos for val split (speech)
Loaded 288 videos for test split (speech)
âœ… Train: 960 samples
âœ… Val: 192 samples
âœ… Test: 288 samples

[3/4] Setting up training...
âœ… Training setup complete

[4/4] Training...
================================================================================

Epoch 1/50
----------------------------------------------------------------------
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 120/120 [01:02<00:00, 1.92it/s, loss=1.8234, acc=35.23%]
Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:08<00:00, 2.85it/s]

Results:
  Train Loss: 1.8234, Acc: 35.23%
  Val Loss: 1.6543, Acc: 42.15%
  LR: 1.00e-04
  ğŸ‰ New best! Val Acc: 42.15%
  âœ… Saved: best_model.pth

...

Epoch 50/50
----------------------------------------------------------------------
Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 120/120 [01:02<00:00, 1.92it/s, loss=0.2345, acc=92.34%]
Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:08<00:00, 2.85it/s]

Results:
  Train Loss: 0.2345, Acc: 92.34%
  Val Loss: 0.5678, Acc: 82.15%
  LR: 1.23e-06
  ğŸ‰ New best! Val Acc: 82.15%
  âœ… Saved: best_model.pth

================================================================================
Testing on test set...
----------------------------------------------------------------------
Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:12<00:00, 2.91it/s]

Test Results:
  Loss: 0.5892
  Accuracy: 80.45%

================================================================================
âœ… TRAINING COMPLETED!
================================================================================

Results:
  Best Val Acc: 82.15%
  Test Acc: 80.45%
  Total Epochs: 50

Checkpoints saved in: /content/drive/MyDrive/checkpoints/multimodal_fer
================================================================================
```

---

## âš™ï¸ Configuration Options

### Model Type:

```python
# Lightweight (faster, ~80-82% accuracy)
"model_type": "lightweight"

# Full (slower, ~82-85% accuracy)
"model_type": "full"
```

### Batch Size:

```python
# Náº¿u bá»‹ OOM (Out of Memory):
"batch_size": 4,
"grad_accum_steps": 4,  # Effective batch size = 16

# Náº¿u cÃ³ nhiá»u VRAM:
"batch_size": 16,
"grad_accum_steps": 1,
```

### Training Duration:

```python
# Quick test (10 phÃºt):
"max_epochs": 5

# Normal training (1.5 giá»):
"max_epochs": 50

# Extended training (3 giá»):
"max_epochs": 100
```

### Modality:

```python
# Speech (recommended, 1440 videos):
"modality": "speech"

# Song (optional, 1012 videos):
"modality": "song"
```

---

## ğŸ” Verify Dataset TrÆ°á»›c Khi Train

```python
# Cell: Test dataset loader
from data.simple_ravdess_dataset import SimpleRAVDESSDataset

# Update path
RAVDESS_PATH = "/content/drive/MyDrive/RAVDESS"

# Test
dataset = SimpleRAVDESSDataset(
    data_dir=RAVDESS_PATH,
    split="train",
    modality="speech",
)

print(f"âœ… Found {len(dataset)} training samples")

# Test loading one sample
audio, video, label, metadata = dataset[0]
print(f"\nSample 0:")
print(f"  Audio shape: {audio.shape}")
print(f"  Video shape: {video.shape}")
print(f"  Label: {label} ({dataset.emotion_names[label]})")
print(f"  Filename: {metadata['filename']}")
```

**Expected output:**
```
Loaded 960 videos for train split (speech)
âœ… Found 960 training samples

Sample 0:
  Audio shape: torch.Size([48000])
  Video shape: torch.Size([16, 3, 224, 224])
  Label: 2 (happy)
  Filename: 01-01-03-01-01-01-01.mp4
```

---

## ğŸ“ Checkpoints Structure

```
/content/drive/MyDrive/checkpoints/multimodal_fer/
â”œâ”€â”€ best_model.pth              # Best model (highest val accuracy)
â”œâ”€â”€ checkpoint_epoch_5.pth      # Periodic checkpoint
â”œâ”€â”€ checkpoint_epoch_10.pth
â”œâ”€â”€ checkpoint_epoch_15.pth
â””â”€â”€ training_history.json       # Training metrics
```

### Load Checkpoint:

```python
import torch
from models import MultimodalFER

# Load model
model = MultimodalFER(num_classes=8, num_segments=8)

# Load checkpoint
checkpoint = torch.load("/content/drive/MyDrive/checkpoints/multimodal_fer/best_model.pth")
model.load_state_dict(checkpoint["model_state_dict"])

print(f"Loaded model from epoch {checkpoint['epoch']}")
print(f"Val accuracy: {checkpoint['val_acc']:.2f}%")
```

---

## ğŸ› Troubleshooting

### Issue 1: "RAVDESS path not found"

**Solution:**
```python
# Check if path exists
import os
path = "/content/drive/MyDrive/RAVDESS"
print(os.path.exists(path))
print(os.listdir("/content/drive/MyDrive"))

# Update CONFIG with correct path
```

### Issue 2: "Found 0 videos"

**Solution:**
```python
# Check folder structure
from pathlib import Path
ravdess_path = Path("/content/drive/MyDrive/RAVDESS")

# List all .mp4 files
videos = list(ravdess_path.rglob("*.mp4"))
print(f"Found {len(videos)} videos")

# Check first few
for v in videos[:5]:
    print(v)
```

### Issue 3: Out of Memory (OOM)

**Solution:**
```python
# Reduce batch size in CONFIG
"batch_size": 4,
"grad_accum_steps": 4,
```

### Issue 4: "ffmpeg not found"

**Solution:**
```python
# Install ffmpeg in Colab
!apt-get install -y ffmpeg

# Or disable audio extraction
"use_audio": False,  # Will use zeros for audio
```

### Issue 5: Training too slow

**Solution:**
```python
# Use lightweight model
"model_type": "lightweight",

# Reduce epochs
"max_epochs": 30,

# Increase batch size (if VRAM allows)
"batch_size": 16,
```

---

## ğŸ“Š Monitor Training

### Option 1: Watch Output

Training progress is printed in real-time:
```
Epoch 25/50
Training: 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 54/120 [00:28<00:34, 1.91it/s, loss=0.4123, acc=85.67%]
```

### Option 2: Check History File

```python
import json

with open("/content/drive/MyDrive/checkpoints/multimodal_fer/training_history.json") as f:
    history = json.load(f)

# Plot
import matplotlib.pyplot as plt

epochs = [h["epoch"] for h in history]
train_acc = [h["train_acc"] for h in history]
val_acc = [h["val_acc"] for h in history]

plt.plot(epochs, train_acc, label="Train")
plt.plot(epochs, val_acc, label="Val")
plt.xlabel("Epoch")
plt.ylabel("Accuracy (%)")
plt.legend()
plt.show()
```

### Option 3: Use WandB

```python
# Enable in CONFIG
"use_wandb": True,
"wandb_project": "multimodal-fer-ravdess",

# Login to WandB
import wandb
wandb.login()

# Then run training
!python colab_train_easy.py
```

---

## âœ… Summary

### Data Pipeline: âœ… HOÃ€N THIá»†N 100%

```
âœ… Automatic file discovery
âœ… Filename parsing
âœ… Audio extraction (ffmpeg)
âœ… Video frame extraction (opencv)
âœ… Train/val/test splitting
âœ… Batch loading
âœ… Works with ANY folder structure
```

### Usage: âœ… Cá»°C Ká»² ÄÆ N GIáº¢N

```
1. Mount Drive
2. Update RAVDESS_PATH
3. Run script
```

### Expected Results:

```
Lightweight: ~80-82% accuracy in ~1.5 hours
Full: ~82-85% accuracy in ~2 hours
```

---

## ğŸ‰ Báº¡n ÄÃ£ Sáºµn SÃ ng!

Chá»‰ cáº§n:
1. Copy Ä‘Æ°á»ng dáº«n RAVDESS cá»§a báº¡n
2. Paste vÃ o `CONFIG["RAVDESS_PATH"]`
3. Run `!python colab_train_easy.py`

**ÄÃ³ lÃ  táº¥t cáº£!** ğŸš€
